#### python modules ####

import glob
import os

#### CONFIG FILE ####
#which datasets are to be aligned to which hosts and viruses are specified in dsets.yaml
#also whether or not to try to merge R1 and R2
configfile: "../../proj-spcfc/test_short_config.yml"

#this is of the form { dset1: {host: host1, virus: host2, merge: True}, dset2: {host: host2, virus: virus2, merge: False} }

#make four lists, with each entry in each list corresponding to one desired output file

DATASETS = []
SAMPLES = []
HOSTS = []
VIRUSES = []
#also make dictionary MERGE, with key dataset_sample and value True or False
MERGE = {}
INSERTS = []


for dataset in config["datasets"]:
	#get files in directory and strip off "_1.fastq.gz"
	samples = [os.path.basename(f)[:-11] for f in glob.glob("../../data/reads/{}/*_1.fastq.gz".format(dataset))]
	samples = samples + [os.path.basename(f)[:-12] for f in glob.glob("../../data/reads/{}/*_R1.fastq.gz".format(dataset))]
	for sample in samples:
		for insert in config["insert-penalty"].split(","):
			DATASETS.append(dataset)
			SAMPLES.append(sample)
			HOSTS.append(config["datasets"][dataset]["host"])
			VIRUSES.append(config["datasets"][dataset]["virus"])
			MERGE["{}_{}".format(dataset, sample)] = config["datasets"][dataset]["merge"]
			INSERTS.append(insert)


#### local rules ####
localrules: all, rename, copy

#### target files ####
rule all:
	input: 
		"../../out/summary/count_short.txt",
		"../../out/summary/count_mapped.xlsx",
		expand("../../out/{dset}/ints/{samp}.{host}.{virus}.insert{insert}.short.txt", zip, dset = DATASETS, samp=SAMPLES, host=HOSTS, virus=VIRUSES, insert=INSERTS)
		
		

#### merging and dedup ###

rule rename:
	input:
		r1 = "../../data/reads/{dset}/{samp}_R1.fastq.gz",
		r2 = "../../data/reads/{dset}/{samp}_R2.fastq.gz"
	output:
		r1_out = temp("../../out/reads/{dset}/{samp}_1.fastq.gz"),
		r2_out = temp("../../out/reads/{dset}/{samp}_2.fastq.gz")
	shell:
		"""
		cp {input.r1} {output.r1_out}
		cp {input.r2} {output.r2_out}
		"""

rule copy:
	input:
		r1 = "../../data/reads/{dset}/{samp}_1.fastq.gz",
		r2 = "../../data/reads/{dset}/{samp}_2.fastq.gz"
	output:
		r1_out = temp("../../out/reads/{dset}/{samp}_1.fastq.gz"),
		r2_out = temp("../../out/reads/{dset}/{samp}_2.fastq.gz")
	shell:
		"""
		cp {input.r1} {output.r1_out}
		cp {input.r2} {output.r2_out}
		"""

rule dedup:
	input:
		r1 = "../../out/reads/{dset}/{samp}_1.fastq.gz",
		r2 = "../../out/reads/{dset}/{samp}_2.fastq.gz"	
	output:
		R1_clumped = "../../out/{dset}/dedup_reads/{samp}.1.fastq.gz",
		R2_clumped = "../../out/{dset}/dedup_reads/{samp}.2.fastq.gz"
	conda:
		"../envs/bbmap.yml"
	shell:
		"""
		clumpify.sh -Xmx10g in={input.r1} in2={input.r2} out={output.R1_clumped} out2={output.R2_clumped} dedupe subs=0
		"""

rule seqPrep:
	input:
		r1 = "../../out/{dset}/dedup_reads/{samp}.1.fastq.gz",
		r2 = "../../out/{dset}/dedup_reads/{samp}.2.fastq.gz"
	output:
		merged = temp("../../out/{dset}/merged_reads/{samp}.SeqPrep_merged.fastq.gz"),
		proc_r1 = temp("../../out/{dset}/merged_reads/{samp}.SeqPrep_1.fastq.gz"),
		proc_r2 = temp("../../out/{dset}/merged_reads/{samp}.SeqPrep_2.fastq.gz"),
		all = temp("../../out/{dset}/merged_reads/{samp}.all.fastq.gz")
	conda:	
		"../envs/seqprep.yml"
	shell:
		"""
		SeqPrep -f {input.r1} -r {input.r2} -1 {output.proc_r1} -2 {output.proc_r2} -s {output.merged}
		cat {output.proc_r1} {output.proc_r2} {output.merged} > {output.all}
		"""


#### alignments ####

rule index:
	input:
		"../../data/references/{genome}.fa"
	output:
		"../../data/references/{genome}.ann",
		"../../data/references/{genome}.amb",
		"../../data/references/{genome}.bwt",
		"../../data/references/{genome}.pac",
		"../../data/references/{genome}.sa"
	conda: 
		"../envs/bwa.yml"
	shell:
		"bwa index -p ../../data/references/{wildcards.genome} {input}"

#functions for if we did seqPrep or not

def get_all(wildcards):
	if MERGE["{}_{}".format(wildcards.dset, wildcards.samp)] == "True":
		folder = "merged_reads"
	else:
		folder = "combined_reads"
	return "../../out/{}/{}/{}.all.fastq.gz".format(wildcards.dset, folder, wildcards.samp)


rule align_bwa_virus:
	input:
		ann = "../../data/references/{virus}.ann",
		amb = "../../data/references/{virus}.amb",
		bwt = "../../data/references/{virus}.bwt",
		pac = "../../data/references/{virus}.pac",
		sa = "../../data/references/{virus}.sa",
		all = get_all
	output:
		vSing = temp("../../out/{dset}/virus_aligned/{samp}.{virus}.bwa.sam")
	conda: 
		"../envs/bwa.yml"
	threads: 5
	shell:	
		"""
		python ./alignReadsWithBWA.py --threads {threads} --index ../../data/references/{wildcards.virus} --read1 {input.all} --output {output.vSing} --threshold 10 --hflag 200
		"""

rule extract_vAligned:
	input:
		vSing = "../../out/{dset}/virus_aligned/{samp}.{virus}.bwa.sam"
	output:
		svSam = temp("../../out/{dset}/virus_aligned/{samp}.{virus}.bwa.mapped.sam")
	conda:
		"../envs/bwa.yml"
	shell:
		"""
		samtools view -h -F 0x4 -F 0x800 -o {output.svSam} {input.vSing} 
		"""

rule extract_vAligedtoFastq:
	input: 
		svSam = "../../out/{dset}/virus_aligned/{samp}.{virus}.bwa.mapped.sam",
	output:
		svFastq = temp("../../out/{dset}/reads/{samp}.bwa.mappedTo{virus}.fastq.gz"),
	conda:
		"../envs/picard.yml"
	shell:
		"""
		picard SamToFastq I={input.svSam} FASTQ={output.svFastq}
		"""

rule align_bwa_host:
	input:	
		ann = "../../data/references/{host}.ann",
		amb = "../../data/references/{host}.amb",
		bwt = "../../data/references/{host}.bwt",
		pac = "../../data/references/{host}.pac",
		sa = "../../data/references/{host}.sa",
		all = "../../out/{dset}/reads/{samp}.bwa.mappedTo{virus}.fastq.gz"
	params:
		inserts = config["insert-penalty"]

	output:
		expand("../../out/{{dset}}/host_aligned/{{samp}}.{{host}}.bwa.{{virus}}Mappedreads.insert{{insert}}.sam", insert=config["insert-penalty"].split(","))
	conda: 
		"../envs/bwa.yml"
	threads: 5
	shell:		
		"python ./alignReadsWithBWA.py --threads {threads} --index ../../data/references/{wildcards.host} --read1 {input.all} --output {output} --threshold 10 --hflag 200 --insert {params.inserts}"

rule convert:
	input:
		"../../out/{dset}/{host_virus}/{samp}.{host_virus_name}.{alignType}{mapped_type}.sam"
	output:
		bam = "../../out/{dset}/{host_virus}_bam/{samp}.{host_virus_name}.{alignType}{mapped_type}{insert_type}.bam",
		bai = "../../out/{dset}/{host_virus}_bam/{samp}.{host_virus_name}.{alignType}{mapped_type}{insert_type}.bam.bai"
	wildcard_constraints:
		samp = "[\w\d_]+",
		host_virus_name = "[\w\d-]+",
		alignType = "bwaPaired|bwa",
		mapped_type = "|\.[\w\d-]+",
		insert_type = "|\.insert\d"
	conda: 
		"../envs/bwa.yml"	
	shell:
		"""
		samtools view -bhS {input} | samtools sort - -o {output.bam}
		samtools index {output.bam}
		"""

#### perl scripts ####

rule run_int_scripts:
	input:
		hSing = "../../out/{dset}/host_aligned/{samp}.{host}.bwa.{virus}Mappedreads.insert{insert}.sam",
		vSing = "../../out/{dset}/virus_aligned/{samp}.{virus}.bwa.mapped.sam"
	output:
		short = "../../out/{dset}/ints/{samp}.{host}.{virus}.insert{insert}.short.txt"
	shell:
		"""
		perl -I.. ../short.pl --viral {input.vSing} --human {input.hSing} --output {output.short}
		"""
	
#### visualization ####

rule count_mapped:
	input:
		expand("../../out/{dset}/host_aligned_bam/{samp}.{host}.bwa.{virus}Mappedreads.insert{insert}.bam", zip, dset = DATASETS, samp = SAMPLES, host = HOSTS, virus = VIRUSES, insert=INSERTS),
		expand("../../out/{dset}/virus_aligned_bam/{samp}.{virus}.bwa.mapped.bam", zip, dset = DATASETS, samp = SAMPLES, virus = VIRUSES)

	output:
		"../../out/summary/count_mapped.txt"
	conda: 
		"../envs/bwa.yml"
	shell:
		".././count_mapped.sh"

rule plot_mapped:
	input:
		"../../out/summary/count_mapped.txt"
	output:
		"../../out/summary/count_mapped.xlsx"
	conda:
		"../envs/rscripts.yml"
	script:
		"../count_reads.R"
		
rule count_short:
	input: 
		short = expand("../../out/{dset}/ints/{samp}.{host}.{virus}.insert{insert}.short.txt", zip, dset = DATASETS, samp = SAMPLES, host =HOSTS, virus = VIRUSES, insert=INSERTS)

	output:
		"../../out/summary/count_short.txt"
	shell:
		"./count_short {output}"



